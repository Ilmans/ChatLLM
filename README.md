# ChatLLM

Chat with LLM directly in your browser using your own GPU (powered by WebGPU)

![Screenshot 2024-10-02 at 20 43 18](https://github.com/user-attachments/assets/fd1e372e-55ed-4678-8004-cef3abe030dc)

1. Clone the repository
```
git clone https://github.com/zuramai/ChatLLM --recursive
cd ChatLLM
```

2. Install
```
pnpm install
```

3. Run
```
pnpm run dev
```

# License
This project is under MIT License
